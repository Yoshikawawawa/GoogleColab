{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "LOVGEKPY5Bzc",
        "Sf45tJY-Lxqg",
        "tgFGCw9L1tTf",
        "xTODLy8XFUri",
        "WByP2ApT-rao",
        "hu9HGN0t-wZW"
      ],
      "mount_file_id": "1zHJNUoBUqjCFLJQ2vUYY_cO5DqcwtQ_K",
      "authorship_tag": "ABX9TyMgJ+bm4KmaSakN9oRtGK2x",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Yoshikawawawa/GoogleColab/blob/main/Sentiment_Analysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# pip"
      ],
      "metadata": {
        "id": "LOVGEKPY5Bzc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install transformers datasets\n",
        "! pip install fugashi ipadic\n",
        "! pip install sentencepiece\n",
        "#クローン化　\n",
        "!git clone https://github.com/ids-cv/wrime.git"
      ],
      "metadata": {
        "id": "OxDUlAl75F9F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# データ確認・整理"
      ],
      "metadata": {
        "id": "Sf45tJY-Lxqg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "df_wrime = pd.read_table(\"/content/wrime/wrime-ver1.tsv\")#ver1を今回は使用\n",
        "df_wrime.info()"
      ],
      "metadata": {
        "id": "_puULmhnL2Vo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#客観感情を配列\n",
        "emotion_names = ['Anger','Anticipation','Disgust','Fear','Joy','Sadness','Surprise','Trust']\n",
        "df_wrime['readers_emotion_intensities'] = df_wrime.apply(lambda x: [x['Avg. Readers_' + name] for name in emotion_names], axis=1)\n",
        "#感情強度2以上を採用\n",
        "is_target = df_wrime['readers_emotion_intensities'].map(lambda x: max(x) >= 2)\n",
        "df_wrime_target = df_wrime[is_target]"
      ],
      "metadata": {
        "id": "n7Ul9nZsycQA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_wrime['readers_emotion_intensities']"
      ],
      "metadata": {
        "id": "toRhdo4y2oOY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 訓練・テストに分割"
      ],
      "metadata": {
        "id": "tgFGCw9L1tTf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_groups = df_wrime_target.groupby('Train/Dev/Test')\n",
        "df_train = df_groups.get_group('train')\n",
        "df_test = pd.concat([df_groups.get_group('dev'), df_groups.get_group('test')])\n",
        "#訓練データ・テストデータ確認\n",
        "print('train :', len(df_train)) \n",
        "print('test :', len(df_test))"
      ],
      "metadata": {
        "id": "2swREnHd11OZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 事前学習済みモデル読み込み・データ整形"
      ],
      "metadata": {
        "id": "xTODLy8XFUri"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
        "#東北大学の乾研究室のモデルを使用\n",
        "#トークナイザとモデルを読み込む\n",
        "MODEL = 'cl-tohoku/bert-base-japanese-whole-word-masking'\n",
        "tokenizer = AutoTokenizer.from_pretrained(MODEL)\n",
        "model = AutoModelForSequenceClassification.from_pretrained(MODEL, num_labels=8)"
      ],
      "metadata": {
        "id": "wE4amzif8ugU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import Dataset\n",
        "import numpy as np\n",
        "# 1. Transformers用のデータセット形式に変換\n",
        "# pandas.DataFrame -> datasets.Dataset\n",
        "target_columns = ['Sentence', 'readers_emotion_intensities']\n",
        "train_dataset = Dataset.from_pandas(df_train[target_columns])\n",
        "test_dataset = Dataset.from_pandas(df_test[target_columns])\n",
        "# 2. Tokenizerを適用（モデル入力のための前処理）\n",
        "def tokenize_function(batch):\n",
        "    \"\"\"Tokenizerを適用 （感情強度の正規化も同時に実施する）.\"\"\"\n",
        "    tokenized_batch = tokenizer(batch['Sentence'], truncation=True, padding='max_length')\n",
        "    tokenized_batch['labels'] = [x / np.sum(x) for x in batch['readers_emotion_intensities']]  # 総和=1に正規化\n",
        "    return tokenized_batch\n",
        "\n",
        "train_tokenized_dataset = train_dataset.map(tokenize_function, batched=True)\n",
        "test_tokenized_dataset = test_dataset.map(tokenize_function, batched=True)"
      ],
      "metadata": {
        "id": "LW7gtfYT9xJ1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 訓練開始"
      ],
      "metadata": {
        "id": "WByP2ApT-rao"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import TrainingArguments, Trainer\n",
        "from datasets import load_metric\n",
        "from transformers import AutoTokenizer\n",
        "\n",
        "# 評価指標を定義\n",
        "# https://huggingface.co/docs/transformers/training\n",
        "metric = load_metric(\"accuracy\")\n",
        "def compute_metrics(eval_pred):\n",
        "    logits, labels = eval_pred\n",
        "    predictions = np.argmax(logits, axis=-1)\n",
        "    label_ids = np.argmax(labels, axis=-1)\n",
        "    return metric.compute(predictions=predictions, references=label_ids)\n",
        "\n",
        "# 訓練時の設定\n",
        "# https://huggingface.co/docs/transformers/v4.21.1/en/main_classes/trainer#transformers.TrainingArguments\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"test_trainer\",\n",
        "    per_device_train_batch_size=8,\n",
        "    num_train_epochs=1.0,\n",
        "    evaluation_strategy=\"steps\",eval_steps=200)  # 200ステップ毎にテストデータで評価する\n",
        "\n",
        "# Trainerを生成\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_tokenized_dataset,\n",
        "    eval_dataset=test_tokenized_dataset,\n",
        "    compute_metrics=compute_metrics,\n",
        ")\n",
        "\n",
        "# 訓練を実行\n",
        "trainer.train()"
      ],
      "metadata": {
        "id": "KJiDlGfQ-ub6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#学習したものをsave\n",
        "tokenizer.save_pretrained(\"/content/drive/MyDrive\")#保存したい場所を指定\n",
        "model.save_pretrained(\"/content/drive/MyDrive\")#保存したい場所を指定"
      ],
      "metadata": {
        "id": "_c6ndWSdmd7r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 文章から推論"
      ],
      "metadata": {
        "id": "hu9HGN0t-wZW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "# ソフトマックス関数\n",
        "# https://www.delftstack.com/ja/howto/numpy/numpy-softmax/\n",
        "def np_softmax(x):\n",
        "    f_x = np.exp(x) / np.sum(np.exp(x))\n",
        "    return f_x\n",
        "\n",
        "def analyze_emotion(text, show_fig=True):\n",
        "    # 推論モードを有効化\n",
        "    model.eval()\n",
        "\n",
        "    # 入力データ変換 + 推論\n",
        "    tokens = tokenizer(text, truncation=True, return_tensors=\"pt\")\n",
        "    tokens.to(model.device)\n",
        "    preds = model(**tokens)\n",
        "    prob = np_softmax(preds.logits.cpu().detach().numpy()[0])\n",
        "    out_dict = {n: p for n, p in zip(emotion_names, prob)}\n",
        "\n",
        "    # 棒グラフを描画\n",
        "    if show_fig:\n",
        "        sns.set()\n",
        "        plt.figure(figsize=(8, 3))\n",
        "        plt.ylim(0, 1.0)\n",
        "        df = pd.DataFrame(out_dict.items(), columns=['name', 'prob'])\n",
        "        sns.barplot(x='name', y='prob', data=df)\n",
        "        plt.title('入力文 : ' + text)\n",
        "    else:\n",
        "        print(out_dict)\n",
        "#テキスト入力\n",
        "analyze_emotion('')"
      ],
      "metadata": {
        "id": "7mQNVKSJ-6Rd"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}